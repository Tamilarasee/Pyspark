{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00166693",
      "metadata": {
        "id": "00166693"
      },
      "source": [
        "#### In this Video We will Cover\n",
        "- PySpark Dataframe\n",
        "- Reading The Dataset\n",
        "- Checking the Datatypes of the Column(Schema)\n",
        "- Selecting Columns And Indexing\n",
        "- Check Describe option similar to Pandas\n",
        "- Adding Columns\n",
        "- Dropping columns\n",
        "- Renaming Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb37d003",
      "metadata": {
        "id": "fb37d003"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1d46445",
      "metadata": {
        "id": "a1d46445"
      },
      "outputs": [],
      "source": [
        "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "078fccba",
      "metadata": {
        "id": "078fccba",
        "outputId": "147b07a5-8d4c-4aeb-8cab-bf47414b644e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e18fcb00c10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c26ef0966ea3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Dataframe</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.option('header','true').csv('test1.csv')"
      ],
      "metadata": {
        "id": "XKxEUrZYdXyQ",
        "outputId": "3b8418dd-af39-45a5-a138-1bd2fc415d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XKxEUrZYdXyQ",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string, age: string, Experience: string, Salary: string]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.option('header','true').csv('test1.csv').show()"
      ],
      "metadata": {
        "id": "KiWzwYRKdaj7",
        "outputId": "db2bf88e-047c-4dda-af76-a83114058d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KiWzwYRKdaj7",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b7b4a628",
      "metadata": {
        "id": "b7b4a628"
      },
      "outputs": [],
      "source": [
        "## read the dataset\n",
        "# By default - all columns are considered as string --> to infer col types- -inferSchema=True)\n",
        "df_pyspark=spark.read.option('header','true').csv('test1.csv',inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "79a95903",
      "metadata": {
        "id": "79a95903",
        "outputId": "98826c1e-5ea3-49bf-80ad-221abad3c823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Check the schema --> like df.info() in pandas -->helps to identify the datatype of the columns and nullability\n",
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8a0d131b",
      "metadata": {
        "id": "8a0d131b",
        "outputId": "01864dfd-2b48-4f41-8ec1-52695e2e67c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark=spark.read.csv('test1.csv',header=True,inferSchema=True)\n",
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "47a5a108",
      "metadata": {
        "id": "47a5a108",
        "outputId": "8b4112a8-6433-4573-e528-0fa47354daf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Check the schema\n",
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "19da5885",
      "metadata": {
        "id": "19da5885",
        "outputId": "d2116596-ccb5-4174-98ad-02c90deaafdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "type(df_pyspark)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.columns"
      ],
      "metadata": {
        "id": "BWO-PF3-fefr",
        "outputId": "0243e5ef-37ef-4f9d-e541-6c1a00539a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BWO-PF3-fefr",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Name', 'age', 'Experience', 'Salary']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e4a3c8eb",
      "metadata": {
        "id": "e4a3c8eb",
        "outputId": "12207faf-43a5-4877-a04d-c82877a4b0f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Name='Krish', age=31, Experience=10, Salary=30000),\n",
              " Row(Name='Sudhanshu', age=30, Experience=8, Salary=25000),\n",
              " Row(Name='Sunny', age=29, Experience=4, Salary=20000)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_pyspark.head(3)\n",
        "# in pyspark, it gives as a list like below, in pandas , we get the result in dataframe format(like table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5523ae24",
      "metadata": {
        "id": "5523ae24",
        "outputId": "f3f05c23-1789-4adc-8ff5-1029ff141574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.select('Name')\n",
        "# selecting columns --important \"select\""
      ],
      "metadata": {
        "id": "nnsCzAXQf88k",
        "outputId": "8ae2c22a-9a7b-4a67-cdd0-86b3625dd430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nnsCzAXQf88k",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Name: string]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c513816d",
      "metadata": {
        "id": "c513816d",
        "outputId": "5a4627bb-60c8-4318-b7e6-639abc53d081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|     Name|Experience|\n",
            "+---------+----------+\n",
            "|    Krish|        10|\n",
            "|Sudhanshu|         8|\n",
            "|    Sunny|         4|\n",
            "|     Paul|         3|\n",
            "|   Harsha|         1|\n",
            "|  Shubham|         2|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.select(['Name','Experience']).show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#slicing is not possible in pyspark like pandas df[1:5], we can use limit() if needed\n",
        "df_pyspark.limit(2).show()\n"
      ],
      "metadata": {
        "id": "cD71t2XygMHz",
        "outputId": "ff6a177f-0a5e-46e1-b2af-ca15fc77784b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "cD71t2XygMHz",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a8bd20e3",
      "metadata": {
        "id": "a8bd20e3",
        "outputId": "ab0e7d96-3482-4850-e1a4-31fffa672a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'Name'>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_pyspark['Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c3d42722",
      "metadata": {
        "id": "c3d42722",
        "outputId": "26c972f7-4ac0-42a9-9e74-0ee1aaf416ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Name', 'string'), ('age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_pyspark.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.describe()"
      ],
      "metadata": {
        "id": "_roOe6lPjyGx",
        "outputId": "da59ebc5-7a17-4de8-e97b-7da2a2bc8757",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_roOe6lPjyGx",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Name: string, age: string, Experience: string, Salary: string]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fa74b18e",
      "metadata": {
        "id": "fa74b18e",
        "outputId": "20cae565-6c40-4e9b-fd10-16eed5c849a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+------------------+-----------------+------------------+\n",
            "|summary|  Name|               age|       Experience|            Salary|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "|  count|     6|                 6|                6|                 6|\n",
            "|   mean|  NULL|26.333333333333332|4.666666666666667|21333.333333333332|\n",
            "| stddev|  NULL| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
            "|    min|Harsha|                21|                1|             15000|\n",
            "|    max| Sunny|                31|               10|             30000|\n",
            "+-------+------+------------------+-----------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6a8d7b54",
      "metadata": {
        "id": "6a8d7b54"
      },
      "outputs": [],
      "source": [
        "### Adding Columns in data frame\n",
        "# we have to assign it back to the same variable - it does change things in place directly\n",
        "# If that col added already exists, then it will be replaced with new computation values\n",
        "df_pyspark=df_pyspark.withColumn('Experience After 2 year',df_pyspark['Experience']+2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e9ff01ed",
      "metadata": {
        "id": "e9ff01ed",
        "outputId": "ae9dfb98-1403-48f5-fc2c-4289365cd16d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+-----------------------+\n",
            "|     Name|age|Experience|Salary|Experience After 2 year|\n",
            "+---------+---+----------+------+-----------------------+\n",
            "|    Krish| 31|        10| 30000|                     12|\n",
            "|Sudhanshu| 30|         8| 25000|                     10|\n",
            "|    Sunny| 29|         4| 20000|                      6|\n",
            "|     Paul| 24|         3| 20000|                      5|\n",
            "|   Harsha| 21|         1| 15000|                      3|\n",
            "|  Shubham| 23|         2| 18000|                      4|\n",
            "+---------+---+----------+------+-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d98641db",
      "metadata": {
        "id": "d98641db"
      },
      "outputs": [],
      "source": [
        "### Drop the columns\n",
        "df_pyspark=df_pyspark.drop('Experience After 2 year')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e0a2723f",
      "metadata": {
        "id": "e0a2723f",
        "outputId": "892259a9-94bb-40cf-c2e3-3825ae0b889a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5432faa1",
      "metadata": {
        "id": "5432faa1",
        "outputId": "c9c243f8-9cd2-4efa-cc68-031111840e58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "| New Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Rename the columns\n",
        "df_pyspark.withColumnRenamed('Name','New Name').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2e5b7d72",
      "metadata": {
        "id": "2e5b7d72"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f211a741",
      "metadata": {
        "id": "f211a741"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9a80b806",
      "metadata": {
        "id": "9a80b806"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e00f90e8",
      "metadata": {
        "id": "e00f90e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7c6cb899",
      "metadata": {
        "id": "7c6cb899"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2e0a8c75",
      "metadata": {
        "id": "2e0a8c75"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}